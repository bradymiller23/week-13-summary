---
title: "week 13 notes"
format: html
editor: 
  markdown: 
    wrap: 72
---

## Tuesday April 11

```{r}
packages <- c(
    # Old packages
    "ISLR2",
    "dplyr",
    "tidyr",
    "readr",
    "purrr",
    "repr",
    "kableExtra",
    "IRdisplay",
    # NEW
    "torch",
    "torchvision",
    "luz",
    "tidyverse"
)

renv::install(packages)
sapply(packages, require, character.only=TRUE)
```

```{r}
url <- "https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv"

df <- read_csv(url) %>%
    mutate_if(\(x) is.character(x), as.factor) %>%
    mutate(y = Survived) %>%
    select(-c(Name, Survived)) %>%
    (\(x) {
        names(x) <- tolower(names(x))
        x
    })
```

```{r}
# url <- "https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data"

# col_names <- c("id", "diagnosis", paste0("feat", 1:30))

# df <- read_csv(
#         url, col_names, col_types = cols()
#     ) %>% 
#     select(-id) %>% 
#     mutate(y = ifelse(diagnosis == "M", 1, 0)) %>%
#     select(-diagnosis)


# df %>% head
```

```{r}
k <- 5

test_ind <- sample(
    1:nrow(df), 
    floor(nrow(df) / k),
    replace=FALSE
)

df_train <- df[-test_ind, ]
df_test  <- df[test_ind, ]

nrow(df_train) + nrow(df_test) == nrow(df)
```

```{r}
fit_glm <- glm(
    y ~ ., 
    df_train %>% mutate_at("y", factor), 
    family = binomial()
)

glm_test <- predict(
    fit_glm, 
    df_test,
    output = "response"
)

glm_preds <- ifelse(glm_test > 0.5, 1, 0)
table(glm_preds, df_test$y)
```

```{r}
NNet <- nn_module(
  initialize = function(p, q1, q2, q3) {  
    self$hidden1 <- nn_linear(p, q1)
    self$hidden2 <- nn_linear(q1, q2)
    self$hidden3 <- nn_linear(q2, q3)
    self$output <- nn_linear(q3, 1)
    self$activation <- nn_relu()
    self$sigmoid <- nn_sigmoid()
  },
    
  forward = function(x) {
    x %>% 
      self$hidden1() %>% self$activation() %>% 
      self$hidden2() %>% self$activation() %>% 
      self$hidden3() %>% self$activation() %>% 
      self$output() %>% self$sigmoid()
  }
)
```

```{r}
# fitting a model without an intercept - when its zero, everything else is zero
M <- model.matrix(y ~ 0 + ., data = df_train)
# model.matrix(y ~ ., data = df_train) [ ,-1]

fit_nn <- NNet %>%
    #
    # Setup the model
    #
    setup(
        loss = nn_bce_loss(),
        optimizer = optim_adam, 
        metrics = list(
            luz_metric_accuracy()
        )
    ) %>% 
    #
    # Set the hyperparameters
    #
    set_hparams(p=ncol(M), q1=256, q2=128, q3=64) %>% 
    set_opt_hparams(lr=0.005) %>% 
    #
    # Fit the model
    #
    fit(
        data = list(
            model.matrix(y ~ 0 + ., data = df_train),
            df_train %>% select(y) %>% as.matrix
        ),
        valid_data = list(
            model.matrix(y ~ 0 + ., data = df_test),
            df_test %>% select(y) %>% as.matrix
        ),
        epochs = 50, 
        verbose = TRUE
    )
```

```{r}
plot(fit_nn)
```

```{r}
nn_test <- predict(
    fit_nn, 
    model.matrix(y ~ . - 1, data = df_test)
)
# nn_test
nn_preds <- ifelse(nn_test > 0.5, 1, 0)

table(nn_preds, df_test$y)
```

```{r}
mean(nn_preds == df_test$y)
```

```{r}
table(glm_preds, df_test$y)
```

```{r}
mean(glm_preds == df_test$y)
```

#### DataLoaders

-   key component in the ML pipeline
-   handle loading and preprocessing of data in efficient way for
    training and evaluating models
-   make it easy to work with large datasets (ex. dataset with trillions
    of bits)
    -   Loading data in smaller batches called chunks
-   Advantages

1.  Efficiency memory management
2.  Parallelism
3.  Preprocessing
4.  Flexibility
5.  Standardization

-   involves partitioning data into smaller chunks (batches)
-   inside one large epoch of gradient descent, it'll break up the data
    into batches and mini gradient descents (does gradient descent on
    every batch)
-   IS DIFFERENT FROM CROSS VALIDATION
-   training data is split up into smaller chunks - data is being cycled
    through during gradient descent
-   if batches are fixed statically (first 100 are batch 1, next 100 are
    batch 2), this is going to introduce some bias into the gradient
    descent process, so you want to shuffle the data between every epoch
-   DataLoader takes care of these issues

```{r}
dir <- "./mnist"

train_ds <- mnist_dataset(
    root = dir,
    train = TRUE,
    download = TRUE,
    transform = transform
)
test_ds <- mnist_dataset(
    root = dir,
    train = FALSE,
    download = TRUE,
    transform = transform
)

```

```{r}
typeof(train_ds)
length(train_ds)
```

```{r}
# 42,000nd  observation is a 28x28 matrix
# one row is a 28x28 matrix
# is an image where a value specifies the intensity of the pixels in the 28x28 image
train_ds$data[42000, ,]
```

Using the data to determine the value of a handwritten number

```{r}
# multi-nomial classification with 10 classes (0,1,2,...,9)

# collection of {x_i, y_i} where i = 1, ranging to 10000
# x_i is 28x28 image of handwritten image
# every y_i {0,1,...,9}
options(repr.plot.width = 10, repr.plot.height = 10)

i <- sample(1:length(train_ds), 1)
x <- train_ds$data[i, ,] %>% t

image(x[1:28, 28:1], useRaster = TRUE, axes = FALSE, col = gray.colors(1000),
      main = train_ds$targets[i]-1 )
```

Displaying multiple handwritten digits and their respective prediction

```{r}
options(repr.plot.width = 10, repr.plot.height = 10)
par(mfrow=c(3,3))

for(iter in 1:9){
    i <- sample(1:length(train_ds), 1)
    x <- train_ds$data[i, ,] %>% t
    image(x[1:28, 28:1], useRaster = TRUE, axes = FALSE, col = gray.colors(1000),
          main = train_ds$targets[i]-1)
}
```

-   data frame with each row being a single image observation and its
    actual value
-   p (# cols) = \# of pixels in width\^2 so you can have column for
    each pixel

```{r}
# splitting up batches into size 128
# shuffling allows to negate any bias by shuffling observations for each epoch
train_dl <- dataloader(train_ds, batch_size = 2000, shuffle = TRUE)
test_dl <- dataloader(test_ds, batch_size = 2000)
```

```{r}
NNet_10 <- nn_module(
  initialize = function(p, q1, q2, q3, o) {
    self$hidden1 <- nn_linear(p, q1)
    self$hidden2 <- nn_linear(q1, q2)
    self$hidden3 <- nn_linear(q2, q3)
    self$OUTPUT <- nn_linear(q3, o)
    self$activation <- nn_relu()
  },
  forward = function(x) {
    x %>%
      self$hidden1() %>%
      self$activation() %>%
      self$hidden2() %>%
      self$activation() %>%
      self$hidden3() %>%
      self$activation() %>%
      self$OUTPUT()
  }
)

fit_nn <- NNet_10 %>%
    #
    # Setup the model
    #
    setup(
        # bce for binary (2 classes) and cross_entropy for multi-class
        loss = nn_cross_entropy_loss(),
        optimizer = optim_adam,
        metrics = list(
            luz_metric_accuracy()
        )
    ) %>%
    #
    # Set the hyperparameters
    #
    set_hparams(p = 28*28, q1 = 256, q2 = 128, q3 = 64, o = 10) %>% 
    #
    # Fit the model
    #
    fit(
        epochs = 10,
        data = train_dl,
        #valid_data = test_dl,
        verbose = TRUE
    )
```

```{r}
NN10_preds <- fit_nn %>% 
  predict(test_ds) %>% 
  torch_argmax(dim = 2) %>%
  as_array()

NN10_preds - 1
```

```{r}
xs <- predict(fit_nn, test_ds) [10, ]
probs <- exp(xs) / sum(exp(xs))
probs


options(repr.plot.width = 10, repr.plot.height = 10)

i <- sample(1:length(train_ds), 1)
x <- train_ds$data[10, ,] %>% t

image(x[1:28, 28:1], useRaster = TRUE, axes = FALSE, col = gray.colors(1000))
```

```{r}
probs %>% torch_argmax() - 1
```

Accuracy

```{r}
mean(NN10_preds == test_ds$targets)
```

Confusion matrix

```{r}
table(NN10_preds, test_ds$targets)
```

```{r}
caret::confusionMatrix(
  NN10_preds %>% as.factor, 
  test_ds$targets %>% as.factor
)
```

## Thursday April 13

#### Unsupervised learning

-   Don't have access to labelled data
-   Don't know ground truth
-   Identify interesting relationships between the x's

1.  Dimension reduction

-   can we discover subgroups of variables $X_1, X_2, ..., X_p$, which
    behave similarly?
-   subsetting based on how similar they are

1.  clustering

-   can we discover subgroups of observations 1, 2, ..., n which behave
    similarly
-   do for observations

**Principle Component Analysis**

given variables and produces low dimension representation of the dataset
(creating lower dimension dataset)

compressing data from each row/observation into 2 variables
